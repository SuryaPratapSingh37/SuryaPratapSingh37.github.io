
<!DOCTYPE html>
<html lang="en-US">
<!-- ! Don't use autoformat in this page -->

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Yulun Zhuang | Robotics PhD at UMich</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Yulun Zhuang" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Robotics PhD at UMich" />
<meta property="og:description" content="Robotics PhD at UMich" />
<link rel="canonical" href="https://silvery107.github.io/" />
<meta property="og:url" content="https://silvery107.github.io/" />
<meta property="og:site_name" content="Yulun Zhuang" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Yulun Zhuang" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","description":"Robotics PhD at UMich","headline":"Yulun Zhuang","name":"Yulun Zhuang","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://silvery107.github.io/assets/img/head.png"}},"url":"https://silvery107.github.io/"}</script>
<!-- End Jekyll SEO tag -->

  <link rel="stylesheet" href="/assets/css/style.css?v=87b6d013005c65fccd6ea3166bf5af3ac6e42068">
  <link rel="stylesheet" href="../assets/fontawesome/css/all.min.css">

  <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-H2H5LCSDZ9"></script>
  <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-H2H5LCSDZ9');
  </script>



<!-- You can set your favicon here -->
<!-- <link rel="icon" href="" type="image/x-icon"> -->
<link rel="apple-touch-icon" sizes="180x180" href="assets/img/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="assets/img/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="assets/img/favicon/favicon-16x16.png">
<link rel="manifest" href="assets/img/favicon/site.webmanifest">

<script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
<!-- end custom head snippets -->

</head>

<body>
  <div class="wrapper">
    <header>
      
      
      <img src="/assets/img/head.png" alt="Logo" width="200" class="round_img"/>
      
      <br>
      <h1 style="margin: 0; text-align: center;">Yulun Zhuang</a></h1>
      <p style="text-align: center;">Robotics PhD at UMich</p>

      <!-- Navigation Buttons -->
<table class="jump_link">
	<tbody>
		<tr>
			<td>
				<a href="#pro" class="jump_link">
					<button class="button">Highlight Projects</button>
				</a>
			</td>
		</tr>
		<tr>
			<td>
				<a href="#pub" class="jump_link">
					<button class="button">Publications</button>
				</a>
			</td>
		</tr>
		<tr>
			<td>
				<a href="#edu" class="jump_link">
					<button class="button">Education</button>
				</a>
			</td>
		</tr>
	</tbody>
</table>

<!-- Media Links with Logo -->
<div class="icon-links">
<!-- ! CV -->
    <div class="sub-link">
        <a href="https://silvery107.github.io" target="_blank">
            <i class="fa-solid fa-file-pdf fa-2x fa-fw"></i>
        </a>
    </div>
<!-- ! Github -->
    <div class="sub-link">
        <a href="https://github.com/silvery107" target="_blank">
            <i class="fa-brands fa-square-github fa-2x fa-fw"></i>
        </a>
    </div>
<!-- ! LinkedIn -->
    <div class="sub-link">
        <a href="https://www.linkedin.com/in/yulun107" target="_blank">
            <i class="fa-brands fa-linkedin fa-2x fa-fw"></i>
        </a>
    </div>
<!-- ! Steam -->
    <!-- <div class="sub-link">
        <a href="https://steamcommunity.com/id/silvery107" target="_blank">
            <i class="fa-brands fa-square-steam fa-2x fa-fw"></i>
        </a>
    </div> -->
<!-- ! Google Scholar -->
    <div class="sub-link">
        <a href="https://scholar.google.com.sg/citations?hl=en&user=z_gDNE0AAAAJ" target="_blank">
            <i class="fa-brands fa-google-scholar fa-2x fa-fw"></i>
        </a>
    </div>
</div>

<!-- ! Email -->
<div class="icon-links">
    <div class="sub-link">
        <a href="mailto:yulunz@umich.edu" target="_blank">
            <i class="fa-solid fa-square-envelope fa-2x fa-fw"></i>
        </a>
    </div>
    <div class="sub-link">
        yulunz@umich.edu
    </div>
</div>

    </header>

    <section>

      <a id="top"></a>

<h1>About Me</h1>

<!-- <p style="font-size:18px; color:black">
    <b>Incoming PhD at UMich in Fall 2024!! </b>
    <br> 
    <b>Thank you to everyone who supported and helped me during the application season!</b>
</p> -->

<p style="font-size:18px">
    I am a PhD student of Robotics Department at University of Michigan (<a href="https://robotics.umich.edu/" target="_blank">UMich</a>), where I work on legged robot control and learning with professor <a href="https://sites.google.com/view/yanranding/home/" target="_blank">Yanran Ding</a> and previously collaborated with Dr. Maani Ghaffari and Dr. Elena Shrestha.
    Prior to that, I received my bachelor degree from Southern University of Science and Technology (<a href="https://mee.sustech.edu.cn/en" target="_blank">SUSTech</a>), majoring in Robotics Engineering. Advised by professor <a href="https://www.wzhanglab.site/members/" target="_blank">Wei Zhang</a>, I had a great research experience on MPC and RL of quadruped robots.
</p>
<!-- 
    I am broadly interested in robotics <b>perception, planning and control</b>, with a focus on developing efficient and deployable algorithms for <b>mobile robots</b>.
 -->
<p style="font-size:18px">
    I am particularly interested in <b>agile legged locomotion</b> in dynamic environments, with a focus on <b>control and learning</b> methods,
    and proficient in developing <b>efficient and deployable</b> robotic algorithms.
    <!-- Apart from my professional endeavors, I have a deep passion for competitive programming and tinkering small DIY projects. -->
    When I'm not immersed in technology, you can find me swimming or playing badminton.
</p>

<h1>Experience</h1>
<table class="experience">
  <tbody>
    <!-- !UMich -->
    <tr>
      <td>
        <img width="50" src="assets/img/U-M_Logo-Hex.png">
      </td>
      <td>
        <font color="black"><b>Research Assistant</b></font>
        <br>
        Aug 2022 - Present, University of Michigan, Ann Arbor, MI, US
      </td>
    </tr>
    <!-- !PlusAI -->
    <tr>
      <td>
        <img width="50" src="assets/img/plusai.png">
      </td>
      <td>
        <font color="black"><b>Software Engineer Intern on Motion Planning</b></font>
        <br>
        May 2023 - Aug 2023, PlusAI Inc., Santa Clara, CA, US
      </td>
    </tr>
    <!-- !NUS -->
    <tr>
      <td>
        <img width="50" src="assets/img/NUS_logo.png">
      </td>
      <td>
        <font color="black"><b>Visiting Student</b></font>
        <br>
        Aug 2021 - Sep 2021, National University of Singapore, Singapore
      </td>
    </tr>
    <!-- !THU -->
    <tr>
      <td>
        <img width="50" src="assets/img/Tsinghua-min.png">
      </td>
      <td>
        <font color="black"><b>Research Intern</b></font>
        <br>
        Jun 2021 - Jul 2021, Tsinghua University, Beijing, China
      </td>
    </tr>
    <!-- !ND -->
    <!-- <tr>
      <td>
        <img width="50" src="assets/img/logo-nd-square.png">
      </td>
      <td>
        <font color="black"><b>University of Notre Dame, US</b></font>
        <br>
        Jun 2020 - Aug 2020, Research Intern
      </td>
    </tr> -->
  </tbody>
</table>


<h1 id="pro">Highlight Projects</h1>
<table class="projects">
  <tbody>
    <!-- ! Deep RL for MPC Control of Quadruped Locomotion -->
    <tr><td>
      <div class="project_cell">
        <img src="assets/img/MPC_Stair_Demo.gif" width="250" class="zoom">
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Hierarchical RL for MPC of Quadruped Locomotion</b></font>
        </p>
        <p>
          <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/rl-mpc-locomotion?style=plastic&logo=github">
          [<a href="https://github.com/silvery107/rl-mpc-locomotion" target="_blank">
            Code
          </a>]
          [<a href="https://docs.google.com/presentation/d/18bznpYrkCPnhCisySPDz18hvL3Ytere7JiJEbdLvpgU/edit?usp=sharing" target="_blank">
            Slides
          </a>]
          <!-- [<a href="assets/img/MPC_Sim2Real.gif" target="_blank">
            Sim2Real
          </a>] -->
          [<a href="assets/img/RL_Paraller_16.gif" target="_blank">
            Parallel Training
          </a>]
          <br>
          Fast simulation and RL training framework for a quadruped locomotion task by dynamically predicting the weight parameters of a MPC controller. The control framework is a hierarchical controller composed of a higher-level policy network and a lower-level model predictive controller.
        </p>
      </div>
    </td></tr>
    <!-- ! Motion Planning Practice -->
    <tr><td>
      <div class="project_cell">
        <img src="assets/img/mp_practice.gif" width="250" class="zoom">
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Motion Planning Practice</b></font>
        </p>
        <p>
          <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/motion-planning-practice?style=plastic&logo=github">
          [<a href="https://github.com/silvery107/motion-planning-practice" target="_blank">
            Code
          </a>]
          [<a href="docs/kinodynamic_rrt.pdf" target="_blank">
            PDF
          </a>]
          <br>
          Fast motion planning algorithm implementations with planar hovercraft and 7-DOF KUKA arm demos in pybullet. Algorithms including Kinodynamic RRT-Connect, RRT-Connect, A*, Iterative IK, lazy-rebuilt KD-Tree and more. Code optimized for readability and efficiency.
        </p>
      </div>
    </td></tr>
    <!-- ! Bayesian Optimization for MPPI Planar Pushing -->
    <tr><td>
      <div class="project_cell">
        <img src="assets/img/bayesian_opt_demo.gif" width="250" class="zoom">
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Bayesian Optimization for MPPI Planar Pushing</b></font>
        </p>
        <p>
          <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/bayesian-opt-gpytorch?style=plastic&logo=github">
          [<a href="https://github.com/silvery107/bayesian-opt-gpytorch" target="_blank">
            Code
          </a>]
          [<a href="docs/Bayesian_Optimization_for_MPPI_Planar_Pushing_Report.pdf" target="_blank">
            PDF
          </a>]
          [<a href="assets/img/bayesian_opt_algorithm.png" target="_blank">
            BOA
          </a>]
          <br>
          Self implemented Bayesian Optimization Algorithm (BOA) in PyTorch for automatically tuning the hyperparameter of Model Predictive Path Integral (MPPI) control to solve a planar box pushing task with non-trivial obstacles.
        </p>
      </div>
    </td></tr>
    <!-- ! Dynamic Object Removing SLAM with MonoRec -->
    <tr><td>
      <div class="project_cell">
        <img src="assets/img/monorec_slam_demo.gif" width="250" class="zoom">
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Dynamic Object Removing SLAM with MonoRec</b></font>
        </p>
        <p>
          <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/monorec-slam?style=plastic&logo=github">
          [<a href="https://github.com/silvery107/monorec-slam" target="_blank">
            Code
          </a>]
          [<a href="docs/monorec_slam_report.pdf" target="_blank">
            PDF
          </a>]
          [<a href="assets/img/monorec_slam_system.png" target="_blank">
            System Diagram
          </a>]
          <br>
          We present a dynamic object removing SLAM method named MonoRec-SLAM. 
          Our method adapts the MaskModule from MonoRec and achieves an average APE improvement by 6.03% on KITTI dataset, obtains a more static map of the scenes, and achieves a great balance between real-time capability and dynamic object masking.
        </p>
      </div>
    </td></tr>
    <!-- ! Single-Image to Camera Pose with iNeRF and PoseCNN -->
    <tr><td>
      <div class="project_cell">
        <img src="assets/img/fast_inerf_demo.gif" width="250" class="zoom">
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Single-Image to Camera Pose with iNeRF and PoseCNN</b></font>
        </p>
        <p>
          <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/fast-inerf?style=plastic&logo=github">
          [<a href="https://github.com/silvery107/fast-inerf" target="_blank">
            Code
          </a>]
          [<a href="docs/fast_inerf_report.pdf" target="_blank">
            PDF
          </a>]
          [<a href="assets/img/fast_inerf_system.png" target="_blank">
            System Diagram
          </a>]
          <br>
          We present an efficient and robust system for view synthesis and pose estimation by integrating PoseCNN and iNeRF. Our method leverages the pose and object segmentation predictions from PoseCNN to improve the initial camera pose estimation and accelerate the optimization process in iNeRF.
        </p>
      </div>
    </td></tr>
    <!-- ! ROB 550 Botlab -->
    <tr><td>
      <div class="project_cell">
        <video src="assets/videos/Kinapped_cat_crop.mp4" width="250" controls muted autoplay loop></video>
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Autonomous SLAM and Exploration with MBot</b></font>
        </p>
        <p>
          <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/silvery-botlab-f22?style=plastic&logo=github">
          [<a href="https://github.com/silvery107/silvery-botlab-f22" target="_blank">
            Code
          </a>]
          [<a href="https://github.com/silvery107/silvery-botlab-f22/blob/main/data/S2T1_Botlab_Report.pdf" target="_blank">
            PDF
          </a>]
          <br>
          In the Botlab, movement control, obstacle detection, maze exploration, and self-localization functionality was developed on the MBot robot, a mobile robot platform.
          It is designed to explore the fundamentals of robot autonomy by developing MBot with autonomous mapping, localization, and exploration capabilities. 
          <b>Winner</b> among 24 teams in the final competition.
        </p>
      </div>
    </td></tr>
    <!-- ! ROB 550 Armlab -->
    <tr><td>
      <div class="project_cell">
        <img src="assets/img/stack_16_high_crop.gif" height="190" class="zoom">
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Robust Detecting and Palletizing with Robot Arm</b></font>
        </p>
        <p>
          <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/silvery-armlab-f22?style=plastic&logo=github">
          [<a href="https://github.com/silvery107/silvery-armlab-f22" target="_blank">
            Code
          </a>]
          [<a href="https://github.com/silvery107/silvery-armlab-f22/blob/master/config/s2_t5_armlab_f22_CV.pdf" target="_blank">
            CV PDF
          </a>]
          [<a href="https://github.com/silvery107/silvery-armlab-f22/blob/master/config/s2_t5_armlab_f22_RC.pdf" target="_blank">
            Control PDF
          </a>]
          <!-- [<a href="assets/img/block_detection.png" target="_blank">
            Block Detections
          </a>] -->
          <br>
          In the Armlab, a 5-DOF robotic arm fully autonomously arranges blocks of different sizes, colors and positions into the desired arrangement. Analytical inverse kinematics is used to determine the appropriate waypoints. An overhead LiDAR Camera is utilized to identify blocks on the board.
          <b>Winner</b> among 24 teams in the final competition.
        </p>
      </div>
    </td></tr>
    <!-- ! Mobile Robot Navigation and Control Capstone-->
    <!-- <tr><td>
      <div class="project_cell">
        <video src="assets/videos/ee346-demo.mp4" width="250" controls muted autoplay loop></video>
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Navigation and Lane Following with TurtleBot3</b></font>
        </p>
        <p>
          <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/ee346-capstone-control?style=plastic&logo=github">
          [<a href="https://github.com/silvery107/ee346-capstone-control" target="_blank">
            Code
          </a>]
          [<a href="https://sites.google.com/view/ee346-capstone-22s-cmdzyl/home" target="_blank">
            Website
          </a>]
          <br>
          We achieved a multifunctional and integrated system that includes autonomous navigation, 
          lane following and ArUco detection using TurtleBot3 Burger. 
          Our system is designed for the competition of finishing a specified task sequence.
        </p>
      </div>
    </td></tr> -->
    <!-- ! Agile Waste Sorting with Tossing -->
    <tr><td>
      <div class="project_cell">
        <video src="assets/videos/tossing-video-4-3.mp4" width="250" controls muted autoplay loop></video>
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Agile Waste Sorting with Tossing</b></font>
        </p>
        <p>
          <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/ME336-Yellow-Team-Project?style=plastic&logo=github">
          [<a href="https://github.com/silvery107/ME336-Yellow-Team-Project" target="_blank">
            Code
          </a>]
          [<a href="https://github.com/silvery107/ME336-Yellow-Team-Project/blob/main/projects/ME336_Report.pdf" target="_blank">
            PDF
          </a>]
          <br>
          Implemented the automatic collection and cleaning of images based on MOG2 algorithm.
          Deployed and trained YOLOv5 to achieve quick waste classification.
          Achieved planning for robot arm to pick toss waste on dynamic conveyor belt.
        </p>
      </div>
    </td></tr>
    <!-- ! NMT with Transformer on Multi30K -->
    <!-- <tr><td>
      <div class="project_cell">
        <img src="https://raw.githubusercontent.com/silvery107/nmt-multi30k-pytorch/main/images/tuning.png" 
          width="250" class="zoom">
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>NMT with Transformer on Multi30K</b></font>
        </p>
        <p>
          [<a href="https://github.com/silvery107/nmt-multi30k-pytorch" target="_blank">
            Code
          </a>]
          [<a href="https://github.com/silvery107/nmt-multi30k-pytorch/blob/main/docs/Machine_Learning_Project_NMT.pdf" target="_blank">
            PDF
          </a>]
          <br>
          Implemented a Transformer architecture to realize a full attention neural network that learns to
          translate German to English. The best model gains a BLEU score up to 37.39, when the minimum
          frequency of words is selected to be 3.
        </p>
      </div>
    </td></tr> -->
    <!-- ! Tractor Autonomous Steering Simulation -->
    <!-- <tr><td>
      <div class="project_cell">
        <img src="https://raw.githubusercontent.com/silvery107/ND-agjunction-webots/main/docs/images/tractor_proto.png"
          width="250" class="zoom">
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Tractor Autonomous Steering Simulation</b></font>
        </p>
        <p>
          [<a href="https://github.com/silvery107/ND-agjunction-webots" target="_blank">
            Code
          </a>]
          [<a href="assets/videos/tractor_demo.mp4" target="_blank">
            Video
          </a>]
          <br>
          Developed a medium-fidelity model of two tractors in Webots and implemented the tractor model and
          the control
          algorithm in Webots, including four-wheel steering capability, body suspension and sensors.
          This project is collaborated with SUSTech, ND and AgJunction Inc.
        </p>
      </div>
    </td></tr> -->
    <!-- ! Segway Locomotion -->
    <!-- <tr><td>
      <div class="project_cell">
        <img src="https://raw.githubusercontent.com/silvery107/segway-locomotion-stm32/main/images/image2.png"
          width="250" class="zoom">
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Segway Locomotion</b></font>
        </p>
        <p>
          [<a href="https://github.com/silvery107/segway-locomotion-stm32" target="_blank">
            Code
          </a>]
          [<a href="assets/videos/blancing.mp4" target="_blank">
            Video
          </a>]
          <br>
          This project is the locomotion control for a Segway robot with STM32F1.
          We implemented balance control, speed control, steering control method for the Segway robot
          together with the Bluetooth debugging function.
        </p>
      </div>
    </td></tr> -->
    <!-- ! HCI Gesture Control -->
    <!-- <tr><td>
      <div class="project_cell">
        <video src="assets/videos/hci-demo-thin.mp4" width="250" controls muted autoplay loop></video>
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Gesture Recognition for Mouse and Keyboard Control</b></font>
        </p>
        <p>
          <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/hci-gesture-control?style=plastic&logo=github">
          [<a href="https://github.com/silvery107/hci-gesture-control" target="_blank">
            Code
          </a>]
          <br>
          Used the watershed algorithm to realize skin color image segmentation, implemented gesture
          recognition
          by template matching, and implemented the gesture interaction with mouse and keyboard based on
          <em>Win32
            API</em>.
        </p>
      </div>
    </td></tr> -->
    <!-- ! Fast Photo Mosaic -->
    <!-- <tr><td>
      <div class="project_cell" style="border: none;">
        <img src="https://github.com/silvery107/fast-photo-mosaic/raw/main/images/mixed.png" 
          width="250" class="zoom">
      </div>
      <div class="project_cell" style="border: none;">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Fast Photo Mosaic</b></font>
        </p>
        <p>
          [<a href="https://github.com/silvery107/fast-photo-mosaic" target="_blank">
            Code
          </a>]
          <br>
          Designed a feature descriptor based on the mean histogram of the LAB color space, used the
          pre-computed feature pool to optimize the synthesis speed, and realized the mosaic photo that has
          better performance than Foto-Mosaik-Edda.
        </p>
      </div>
    </td></tr> -->
  </tbody>
</table>


<!-- Let's keep Publications and Patents adjacent  -->
<h1 id="pub">Publications</h1>
<!-- !Sense, Imagine, Act -->
<p style="font-size:18px;margin-bottom: 0px;">
    <font color="black">
        <b>Sense, Imagine, Act: Multimodal Perception Improves Model-Based 
            Reinforcement Learning for Head-to-Head Autonomous Racing</b>
    </font>
    <br>
    <i>arXiv:2305.04750</i>
    <br>
    Shrestha, E., Reddy, C., Wan, H., <b>Zhuang, Y.</b>, & Vasudevan, R. 
</p>
<table class="projects">
    <tbody>
        <tr><td>
            <div class="project_cell">
                <!-- <link rel="preload" as="image" href="assets/img/multi_dreamer.png" media="(max-width: 250px)"> -->
                <img src="assets/img/ral_2023.png" width="250" class="zoom"
                    onmouseover="this.src='assets/img/ral_2023.png'" 
                    onmouseout="this.src='assets/img/ral_2023.png'">
            </div>
            <div class="project_cell">
                <!-- [<a href="https://github.com/silvery107/wheeled-bipedal-jumping" target="_blank">
                    Code
                </a>] -->
                [<a href="assets/videos/racing_overtake.mp4" target="_blank">
                    Video
                </a>]
                [<a href="https://arxiv.org/abs/2305.04750" target="_blank">
                    PDF
                </a>]
                [<a href="assets/img/multi_dreamer.png" target="_blank">
                    Multimodal Dreamer
                </a>]
                <br>
                <p>
                    We present a multimodal perception system combining egocentric LiDAR and RGB camera improves robustness of the world model without requiring additional training data. 
                    The resulting multimodal Dreamer agent safely avoided collisions and won the most races compared to other tested baselines in zero-shot head-to-head autonomous racing. 
                </p>
            </div>
        </td></tr>
    </tbody>
</table>
<!-- !Height Control for Wheeled-Bipedal Robots -->
<p style="font-size:18px;margin-bottom: 0px;">
    <font color="black">
        <b>Height Control and Optimal Torque Planning for Jumping with Wheeled-Bipedal Robots</b>
    </font>
    <br>
    <i>International Conference on Advanced Robotics and Mechatronics</i>. IEEE. 2021
    <br>
    <b>Zhuang, Y.</b>, Xu, Y., ... & Fu, C. 
</p>
<table class="projects">
    <tbody>
        <tr><td>
            <div class="project_cell">
                <link rel="preload" as="image" href="assets/img/ARM2021_4.jpg" media="(max-width: 250px)">
                <img src="assets/img/ARM2021.jpg" width="250" class="zoom"
                    onmouseover="this.src='assets/img/ARM2021_4.jpg'" 
                    onmouseout="this.src='assets/img/ARM2021.jpg'">
            </div>
            <div class="project_cell">
                <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/wheeled-bipedal-jumping?style=plastic&logo=github">
                [<a href="https://github.com/silvery107/wheeled-bipedal-jumping" target="_blank">
                    Code
                </a>]
                [<a href="assets/videos/ARM2021_Video.mp4" target="_blank">
                    Video
                </a>]
                [<a href="https://ieeexplore.ieee.org/document/9536196" target="_blank">
                    PDF
                </a>]
                <br>
                <p>
                    We present a wheeled-bipedal jumping dynamical (W-JBD) model to optimize the height control,
                    and the Bayesian optimization for torque planning (BOTP) method based on a joint
                    optimization framework for torque planning to achieve accurate height control and minimal energy
                    cost.
                </p>
            </div>
        </td></tr>
    </tbody>
</table>

<!-- <h1 id="pat">Patents</h1> -->

<!-- !Nezha Patent -->
<p style="font-size:18px;margin-bottom: 0px;">
    <font color="black">
        <b>Wheeled-Bipedal Robot</b>
    </font>
    <br>
    <font style="font-size:16px">
        [<a href="https://patents.google.com/patent/CN112977666A/en?inventor=%E5%BA%84%E5%AE%87%E4%BC%A6" target="_blank">
            PDF
        </a>]
        [<a href="assets/img/nezha_real.jpg" target="_blank">
            View Robot
        </a>]
    </font>
    <br>
    <i>China Patent</i> CN112977666A Jun 2021
    <br>
    W. Zhang, <b>Y. Zhuang</b>, <i>et al</i>.
</p>
<!-- <table class="projects">
    <tbody>
        <tr>
            <td style="margin-bottom: 20px;">
                <link rel="preload" as="image" href="assets/img/nezha_real.jpg" media="(max-width: 250px)">
                <img src="assets/img/v2-render.png" width="250" class="zoom"
                    onmouseover="this.src='assets/img/nezha_real.jpg'" 
                    onmouseout="this.src='assets/img/v2-render.png'">
            </td>
            <td>
                [<a href="https://patents.google.com/patent/CN112977666A/en?inventor=%E5%BA%84%E5%AE%87%E4%BC%A6" target="_blank">
                    PDF
                </a>]
                <br>
                <p>
                    Mechatronics designed a wheeled-bipedal robot, integrated knee and hip motors by a four-bar linkage.
                    Implemented the electric control system of the robot based on STM32 MCU and UpBoard with Linux.
                    Received the Guangdong "Climbing Program" Special Funds (20,000 CNY).
                </p>
            </td>
        </tr>
    </tbody>
</table> -->

<!-- !Surface Vessels Patent -->
<p style="font-size:18px">
    <font color="black">
        <b>Connecting Structure and Multi-Hull Ship</b>
    </font>
    <br>
    <font style="font-size:16px">
        <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/auto-docking-vessels?style=plastic&logo=github">
        [<a href="https://github.com/silvery107/auto-docking-vessels" target="_blank">
            Code
        </a>]
        [<a href="https://patents.google.com/patent/CN212637810U/en?oq=CN212637810U" target="_blank">
            PDF
        </a>]
        [<a href="assets/img/ship.png" target="_blank">
            View Robot
        </a>]
    </font>
    <br>
    <i>China Patent</i> CN212637810U Mar 2021
    <br>
    <b>Y. Zhuang</b>, W. Zhang, <i>et al</i>.
</p>
<!-- <table class="projects">
    <tbody>
        <tr>
            <td style="border: none;">
                <link rel="preload" as="image" href="assets/img/ship.png" media="(max-width: 250px)">
                <img src="assets/img/ship_render.JPG" width="250" class="zoom"
                    onmouseover="this.src='assets/img/ship.png'" 
                    onmouseout="this.src='assets/img/ship_render.JPG'">
            </td>
            <td style="border: none;">
                [<a href="https://github.com/silvery107/auto-docking-vessels" target="_blank">
                    Code
                </a>]
                [<a href="assets/videos/ship.mp4" target="_blank">
                    Video
                </a>]
                [<a href="https://patents.google.com/patent/CN212637810U/en?oq=CN212637810U" target="_blank">
                    PDF
                </a>]
                <br>
                <p>
                    Designed hybrid-connection autonomous floating vessels.
                    Applied servo motors to switch between rigid ball-socket connections and flexible cable connections.
                    Implemented closed-loop speed control using Kalman filter to estimate the body speed from the IMU and GPS data.
                    Received National Innovation and Entrepreneurship Training Program Funds (10,000 CNY).
                </p>
            </td>
        </tr>
    </tbody>
</table> -->


<h1 id="edu">Education</h1>
<table class="experience">
  <tbody>
    <tr>
      <td>
        <img width="50" src="assets/img/U-M_Logo-Hex.png">
      </td>
      <td>
        <font color="black"><b>University of Michigan, US</b></font>
        <br>
        Aug 2022 - May 2024, Master of Science in Robotics
      </td>
    </tr>
    <tr>
      <td>
        <img width="50" src="assets/img/sustech_square.png">
      </td>
      <td>
        <font color="black"><b>Southern University of Science and Technology, China</b></font>
        <br>
        Sep 2018 - Jun 2022, Bachelor of Engineering in Robotics
      </td>
    </tr>
  </tbody>
</table>


<!-- <h1 id="hon">Honors & Awards</h1> -->
<!-- include awards.html -->

<!-- ! make images in zoom class clickable -->
<div id="image-cover-modal" class="image-cover-modal">
  <img id="image-cover-image" class="image-cover-modal-content">
  <!-- <div id="image-cover-caption"></div> -->
</div>

<script>
// Get the DOM
var modal = document.getElementById('image-cover-modal');
var modalImg = document.getElementById("image-cover-image");
// var captionText = document.getElementById("image-cover-caption");
var span = document.getElementsByClassName("image-cover-close")[0];

// When the user clicks on <span> (x), close the modal
modal.onclick = function() {
    this.classList.remove("model-shown");
}

var i;
var images = document.getElementsByClassName('zoom');
for (i = 0; i < images.length; i++) {

    // Get the image and insert it inside the modal - use its "alt" text as a caption
    var img = images[i];

    img.onclick = function(){
        modal.classList.add("model-shown");
        modalImg.src = this.src;
        // captionText.innerHTML = this.alt;
    }
}
</script>



    </section>

    <footer>
      <!-- ! Back to Top Easy Impl -->
<p style="text-align: center;margin: 20px 0 0;">[<a href="#top">Back to Top</a>]</p>
<!-- ! Dark Mode Switch Easy Impl -->
<p style="text-align: center; margin: 5px 0 0;">Dark Mode <a href="javascript:DarkReader.enable({brightness: 100, contrast: 90, sepia: 10});">ON</a> / <a href="javascript:DarkReader.disable()">OFF</a></p>
    </footer>
  </div>

  <div class="action-button z-depth-1">
    +
    <ul class="action-list">
        <li class="action-list-item">
            <div class="date"></div>
        </li>
    </ul>
  </div>

  <script src="/assets/js/scale.fix.js"></script>
  <!-- ! Last Update Script -->
  <script src="assets/js/last_updated_date.js"></script>
  <!-- ! Action Button Script -->
  <script src="assets/js/action_button.js"></script>
  <!-- ! Canvas Script -->
  <script type="text/javascript" color="0,0,0" opacity='0.7' zIndex="-2" count="80" src="../assets/js/canvas_nest.js"></script>
  <!-- ! Dark Mode Scripts-->
  <script src="https://cdn.jsdelivr.net/npm/darkreader@4.9.58/darkreader.min.js"></script>
  <script src="assets/js/dark_mode.js"></script>
</body>

</html>
