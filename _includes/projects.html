<table class="projects">
  <tbody>
    <!-- ! Multimodal Perception for Autonomous Racing -->
    <tr><td>
      <div class="project_cell">
        <img src="assets/img/placeholder.jpg" width="250" class="zoom">
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Multimodal Perception for Autonomous Racing</b></font>
        </p>
        <p>
          <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/rl-mpc-locomotion?style=plastic&logo=github">
          [<a href="https://github.com/curious-ai/pytorch-td-rex/tree/offline" target="_blank">
            Code
          </a>]
          [<a href="https://docs.google.com/presentation/d/18bznpYrkCPnhCisySPDz18hvL3Ytere7JiJEbdLvpgU/edit?usp=sharing" target="_blank">
            Slides
          </a>]
          [<a href="assets/img/placeholder.jpg" target="_blank">
            Parallel Training
          </a>]
          <br>
          Developed a lightweight UNet model for image segmentation with a Dice metric of 0.99 and streamlining data annotation using SAM. Enhanced sensor fusion by establishing ROS communication at 30 Hz for lidar and RGB cameras, and integrated the Dreamer algorithm with an Offline RL framework to achieve efficient online fine-tuning of the world model directly in the real world with a step ratio of less than 40%.
        </p>
      </div>
    </td></tr>
    <!-- ! ROB 550 MBot-->
    <tr><td>
      <div class="project_cell">
        <img src="assets/img/placeholder.jpg" width="250" class="zoom">
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Motion Planning Practice</b></font>
        </p>
        <p>
          <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/motion-planning-practice?style=plastic&logo=github">
          [<a href="https://github.com/silvery107/motion-planning-practice" target="_blank">
            Code
          </a>]
          [<a href="assets/img/placeholder.jpg" target="_blank">
            PDF
          </a>]
          <br>
          Fast motion planning algorithm implementations with planar hovercraft and 7-DOF KUKA arm demos in pybullet. Algorithms including Kinodynamic RRT-Connect, RRT-Connect, A*, Iterative IK, lazy-rebuilt KD-Tree and more. Code optimized for readability and efficiency.
        </p>
      </div>
    </td></tr>
    <!-- ! Wombat -->
    <tr><td>
      <div class="project_cell">
        <img src="assets/img/placeholder.jpg" width="250" class="zoom">
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Bayesian Optimization for MPPI Planar Pushing</b></font>
        </p>
        <p>
          <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/bayesian-opt-gpytorch?style=plastic&logo=github">
          [<a href="https://github.com/silvery107/bayesian-opt-gpytorch" target="_blank">
            Code
          </a>]
          [<a href="assets/img/placeholder.jpg" target="_blank">
            PDF
          </a>]
          [<a href="assets/img/placeholder.jpg" target="_blank">
            BOA
          </a>]
          <br>
          Self implemented Bayesian Optimization Algorithm (BOA) in PyTorch for automatically tuning the hyperparameter of Model Predictive Path Integral (MPPI) control to solve a planar box pushing task with non-trivial obstacles.
        </p>
      </div>
    </td></tr>
    <!-- ! ROB550 Armlab -->
    <tr><td>
      <div class="project_cell">
        <img src="assets/img/placeholder.jpg" width="250" class="zoom">
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Dynamic Object Removing SLAM with MonoRec</b></font>
        </p>
        <p>
          <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/monorec-slam?style=plastic&logo=github">
          [<a href="https://github.com/silvery107/monorec-slam" target="_blank">
            Code
          </a>]
          [<a href="assets/img/placeholder.jpg" target="_blank">
            PDF
          </a>]
          [<a href="assets/img/placeholder.jpg" target="_blank">
            System Diagram
          </a>]
          <br>
          We present a dynamic object removing SLAM method named MonoRec-SLAM. 
          Our method adapts the MaskModule from MonoRec and achieves an average APE improvement by 6.03% on KITTI dataset, obtains a more static map of the scenes, and achieves a great balance between real-time capability and dynamic object masking.
        </p>
      </div>
    </td></tr>
    <!-- ! Autonomous UAV -->
    <tr><td>
      <div class="project_cell">
        <img src="assets/img/placeholder.jpg" width="250" class="zoom">
      </div>
      <div class="project_cell">
        <p style="font-size:18px;margin-bottom: 0px;">
          <font color="black"><b>Single-Image to Camera Pose with iNeRF and PoseCNN</b></font>
        </p>
        <p>
          <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/silvery107/fast-inerf?style=plastic&logo=github">
          [<a href="https://github.com/silvery107/fast-inerf" target="_blank">
            Code
          </a>]
          [<a href="assets/img/placeholder.jpg" target="_blank">
            PDF
          </a>]
          [<a href="assets/img/placeholder.jpg" target="_blank">
            System Diagram
          </a>]
          <br>
          We present an efficient and robust system for view synthesis and pose estimation by integrating PoseCNN and iNeRF. Our method leverages the pose and object segmentation predictions from PoseCNN to improve the initial camera pose estimation and accelerate the optimization process in iNeRF.
        </p>
      </div>
    </td></tr>
  </tbody>
</table>
